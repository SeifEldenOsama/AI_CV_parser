{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13697670,"sourceType":"datasetVersion","datasetId":8712999}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T17:21:09.874660Z","iopub.execute_input":"2025-11-11T17:21:09.874957Z","iopub.status.idle":"2025-11-11T17:21:11.643832Z","shell.execute_reply.started":"2025-11-11T17:21:09.874912Z","shell.execute_reply":"2025-11-11T17:21:11.643046Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"!pip install langchain langchain-community langchain-core transformers==4.52.4 pydantic torch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T17:45:06.234287Z","iopub.execute_input":"2025-11-11T17:45:06.235179Z","iopub.status.idle":"2025-11-11T17:46:38.414038Z","shell.execute_reply.started":"2025-11-11T17:45:06.235146Z","shell.execute_reply":"2025-11-11T17:46:38.412910Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.27)\nCollecting langchain-community\n  Downloading langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\nRequirement already satisfied: langchain-core in /usr/local/lib/python3.11/dist-packages (0.3.72)\nCollecting transformers==4.52.4\n  Downloading transformers-4.52.4-py3-none-any.whl.metadata (38 kB)\nRequirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (2.12.4)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.4) (3.20.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.4) (0.36.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.4) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.4) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.4) (6.0.3)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.4) (2025.11.3)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.4) (2.32.5)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.4) (0.21.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.4) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.4) (4.67.1)\nRequirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.9)\nRequirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.4.8)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.41)\nINFO: pip is looking at multiple versions of langchain-community to determine which version is compatible with other requirements. This could take a while.\nCollecting langchain-community\n  Downloading langchain_community-0.4-py3-none-any.whl.metadata (3.0 kB)\n  Downloading langchain_community-0.3.31-py3-none-any.whl.metadata (3.0 kB)\nCollecting langchain-core\n  Downloading langchain_core-0.3.79-py3-none-any.whl.metadata (3.2 kB)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.13.2)\nRequirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.1.2)\nRequirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\nRequirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.11.0)\nRequirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.3)\nRequirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (1.33)\nRequirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (4.15.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic) (0.7.0)\nRequirement already satisfied: pydantic-core==2.41.5 in /usr/local/lib/python3.11/dist-packages (from pydantic) (2.41.5)\nRequirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.11/dist-packages (from pydantic) (0.4.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.10.0)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.52.4) (1.2.0)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (3.11.0)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\nRequirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.23.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.52.4) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.52.4) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.52.4) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.52.4) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.52.4) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.52.4) (2.4.1)\nRequirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.52.4) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.52.4) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.52.4) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.52.4) (2025.10.5)\nRequirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.3)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.11.0)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers==4.52.4) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers==4.52.4) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers==4.52.4) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers==4.52.4) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers==4.52.4) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers==4.52.4) (2024.2.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\nDownloading transformers-4.52.4-py3-none-any.whl (10.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading langchain_community-0.3.31-py3-none-any.whl (2.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m80.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_core-0.3.79-py3-none-any.whl (449 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m449.8/449.8 kB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m70.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m74.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, langchain-core, transformers, langchain-community\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n  Attempting uninstall: langchain-core\n    Found existing installation: langchain-core 0.3.72\n    Uninstalling langchain-core-0.3.72:\n      Successfully uninstalled langchain-core-0.3.72\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.53.3\n    Uninstalling transformers-4.53.3:\n      Successfully uninstalled transformers-4.53.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed langchain-community-0.3.31 langchain-core-0.3.79 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 transformers-4.52.4\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer\nfrom langchain.output_parsers import StructuredOutputParser, ResponseSchema\nfrom langchain.prompts import PromptTemplate\nimport torch\nimport re\n\nmodel_name = \"mistralai/Mistral-Nemo-Instruct-2407\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16, device_map=\"auto\")\n\ndef generate_text(prompt, max_length=1000, num_return_sequences=1):\n    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n    outputs = model.generate(\n        **inputs,\n        max_length=max_length,\n        num_return_sequences=num_return_sequences,\n        do_sample=True,\n        top_k=50,\n        top_p=0.95,\n        temperature=0.7,\n    )\n    return [tokenizer.decode(output, skip_special_tokens=True) for output in outputs]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T19:00:15.297678Z","iopub.execute_input":"2025-11-11T19:00:15.297843Z","iopub.status.idle":"2025-11-11T19:03:45.589643Z","shell.execute_reply.started":"2025-11-11T19:00:15.297828Z","shell.execute_reply":"2025-11-11T19:03:45.589001Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c100ad8c79894078b06b7fe537f26794"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fae06dca028341cb96a502e582ffb0d1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6881e6c7dd14a5bb25007932b178365"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/622 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b3fc0411837418aad0e02bb2aa13a39"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n2025-11-11 19:00:36.050656: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1762887636.220981      48 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1762887636.269072      48 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0329f0feffe44b0881849cba7d75d51c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"109fe29ba938447ca8acc078a314daac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00004-of-00005.safetensors:   0%|          | 0.00/4.91G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a176d9d5f086483380dd055cb48b35a2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00005-of-00005.safetensors:   0%|          | 0.00/4.91G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ec0e7936293462580301aff35c5c5fd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00005.safetensors:   0%|          | 0.00/4.91G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6fecc3f24f34b97adf01c73ee5f4740"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00005.safetensors:   0%|          | 0.00/4.87G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"08a626225dfd422c90aec84cacda9951"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00005.safetensors:   0%|          | 0.00/4.91G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d43e7a681d54887a7f35b3d4601c519"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9626888930214c389e5cfbd433ecdae6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a216d1c7c2f94e2a88938c7487ce028f"}},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"from pypdf import PdfReader\nreader = PdfReader(\"/kaggle/input/seifcv/Resume_updated.pdf.pdf\")\ntext = \"\".join(page.extract_text() for page in reader.pages if page.extract_text())\n\n\n\neducation_schema = ResponseSchema(\n    name=\"education\",\n    description=\"A list of the candidate's education entries.\",\n)\n\nexperience_schema = ResponseSchema(\n    name=\"experience\",\n    description=\"A list of the candidate's work experience entries.\",\n)\n\n\nfull_name_schema = ResponseSchema(\n    name=\"full_name\",\n    description=\"The candidate's full name.\",\n)\n\nemail_schema = ResponseSchema(\n    name=\"email\",\n    description=\"The candidate's email address.\",\n)\n\nskills_schema = ResponseSchema(\n    name=\"skills\",\n    description=\"A list of the candidate's technical and soft skills.\",\n)\n\n\n\nresponse_schemas = [\n    full_name_schema,\n    email_schema,\n    education_schema,\n    skills_schema,\n    experience_schema\n]\noutput_parser = StructuredOutputParser.from_response_schemas(response_schemas)\nformat_instructions = output_parser.get_format_instructions()\n\npurchase_extraction_template = \"\"\"\nYou are a highly specialized HR assistant tasked with parsing raw resume text into a structured JSON format.\n\nExtract all relevant information from the resume text based *EXACTLY* on the provided JSON schema.\nIf a field is not present in the text, you must omit it or use an empty list/string as required by the schema.\n\nResume Text:\n\"{text}\"\n\nRespond ONLY in a JSON markdown code block, strictly adhering to the following structure:\n{format_instructions}\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T19:09:20.790719Z","iopub.execute_input":"2025-11-11T19:09:20.791408Z","iopub.status.idle":"2025-11-11T19:09:21.258989Z","shell.execute_reply.started":"2025-11-11T19:09:20.791384Z","shell.execute_reply":"2025-11-11T19:09:21.258409Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"final_prompt = PromptTemplate(\n    template=purchase_extraction_template,\n    input_variables=[\"text\", \"format_instructions\"]\n).format(text=text, format_instructions=format_instructions)\n\nresponse = generate_text(final_prompt, max_length=3000)[0]\nprint(response)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T19:09:23.866537Z","iopub.execute_input":"2025-11-11T19:09:23.866817Z","iopub.status.idle":"2025-11-11T19:10:57.360432Z","shell.execute_reply.started":"2025-11-11T19:09:23.866796Z","shell.execute_reply":"2025-11-11T19:10:57.359554Z"}},"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\nYou are a highly specialized HR assistant tasked with parsing raw resume text into a structured JSON format.\n\nExtract all relevant information from the resume text based *EXACTLY* on the provided JSON schema.\nIf a field is not present in the text, you must omit it or use an empty list/string as required by the schema.\n\nResume Text:\n\"SeifElden Osama\nSoftware Engineer & AI Specialist\n +20 1060381126 | seifosama708@gmail.com\n LinkedIn | GitHub | Kaggle\nProfile Summary\nA 4th-year student and aspiring Software Engineer & AI Specialist, specializing in Machine Learning, Deep\nLearning, and Computer Vision, Proficient in Python, Java, TensorFlow, and PyTorch, with a solid technical\nfoundation in OOP, Data Structures, and Algorithms, Experienced in designing and implementing data-driven\nsolutions and real-time systems, with familiarity in Product and Project Management concepts. Focused on clean\narchitecture, performance optimization, and applying AI to solve real-world challenges.\nTechnical Skills\n• Programming Languages: Python, Java, C++, C#, Dart, SQL, HTML5, JavaScript\n• Core Computer Science Skills: Object-Oriented Programming (OOP), Data Structures & Algorithms,\nProblem Solving (Competitive Programming, Algorithmic Thinking)\n• Databases: MySQL, SQL Server, SQLite\n• AI & Machine Learning Domains:\n• Machine Learning: Supervised Learning, Unsupervised Learning, Feature Engineering,\nModel Evaluation\n• Deep Learning: CNNs, RNNs, LSTMs, Transfer Learning\n• Computer Vision: Image Classification, Object Detection, Image Processing\n• Natural Language Processing (NLP): Text Classification, Sentiment Analysis, Embeddings\n• Speech & Audio AI: Emotion Recognition, MFCC Features, Spectrogram Analysis\n• Predictive Analytics: Regression Models, Time Series Forecasting\n• Frameworks & Tools: TensorFlow, PyTorch, Keras, scikit-learn, NumPy, Pandas, OpenCV, Matplotlib,\nSeaborn, Plotly, Dash\n• Development Tools: JavaFX, Flutter, Swing, Tkinter, Git, GitHub, Arduino\nExperience\nNational Telecommunication Institute (NTI) – ETA Training Program (On-Site) - Egypt (New Capital)\n• Mastered core concepts of AI and Machine Learning, including Supervised and Unsupervised Learning, Feature\nEngineering, and Model Evaluation, as part of the HCIA-AI V4.0 curriculum.\n• Gained advanced practical skills in Deep Learning (CNNs, RNNs, LSTMs, Transfer Learning), Computer Vision\n(Object Detection, Image Processing), and using frameworks like TensorFlow, PyTorch, and Keras to solve\nreal-world problems.\n• Led a team in developing a computer vision solution based on the Huawei curriculum content.\nCodeAlpha – Machine Learning Intern & Python Programming Intern (Remote)\n• Developed ML and deep learning models for credit scoring, emotion recognition, handwriting recognition, and\ndisease prediction using Logistic Regression, Decision Trees, Random Forests, CNNs, RNNs, and XGBoost.\n• Applied feature engineering, MFCC extraction, and model evaluation (Precision, Recall, F1, ROC-AUC) to\ndeliver accurate predictive analytics solutions.\n• Build python applications including automation tools, a rule-based chatbot, and a stock protofolio tracker using\nstrong problem solving and programming skills.\nSaiket Systems – Data Science Intern (Remote)• Performed customer churn analysis with EDA, segmentation, and churn prediction models (Logistic Regression,\nDecision Trees), optimized via feature selection and hyperparameter tuning.\n• Provided actionable business insights on churn drivers and recommended retention strategies to improve\ncustomer loyalty in telecoms.\nCodveda – Machine Learning Intern (Remote)\n• Implemented supervised and unsupervised learning (Regression, KNN, SVM, Random Forest, K-Means) and\ndeep learning models using Python and TensorFlow/Keras.\n• Gained practical experience in preprocessing, feature engineering, cross-validation, visualization, and\nperformance evaluation for end-to-end ML workflows.\nProjects\n• Real-Time Safety Helmet Detection System (Team Leader - Final Project, NTI ETA Training) –\nLed a team in developing a computer vision solution based on the Huawei curriculum content.\nImplemented a fine-tuned YOLO object detection pipeline for real-time helmet/head classification and\nlocalization using Transfer Learning. Developed custom data scripts for VOC to YOLO conversion and\ncoordinate normalization to ensure scale-invariance and robust performance. Achieved high accuracy\n(expected mAP >90%) and fast inference, crucial for automated safety compliance monitoring on\nindustrial sites.\n• Spam Email Classifier – Developed an NLP-based machine learning model that detects and classifies\nspam messages with high precision. Achieved a strong 96% accuracy rate by leveraging text\npreprocessing, feature extraction, and classification algorithms.\n• Gender Classification System – Built a deep learning CNN-based facial image classifier that\ndistinguishes gender from facial features. Reached 98% accuracy using large-scale training data and\nrobust image preprocessing techniques.\n• Interactive Titanic Dashboard – Created an interactive dashboard using Dash & Plotly to visualize\nTitanic passenger survival patterns. Included dynamic filtering, charts, and data exploration features for\ndeeper insights.\n• Image Processing App – Developed a JavaFX desktop application integrated with\nPython backend for advanced image processing. Implemented features like erosion,\ndilation, Gaussian noise, and real-time filtering effects.\n• Film Name Expectation Game – Built a JavaFX-based game integrated with a database\nwhere users guess film names based on actor clues. Added a hint system and scoring\nmechanism to enhance engagement and interactivity.\n• Body Scan Application (Team Leader – Final Project, MEC Academy) – Led a team in developing a\nmedical image classification system using deep learning models, deployed with JavaFX. The application\ndetects Chest X-rays, Diabetic Retinopathy, Brain Tumors, and Bone Fractures with accuracies of 93%,\n90%, 89%, and 98%, respectively, each integrated with backend Flask APIs for real-time predictions.\nOversaw project design, model integration, and UI development with styled result windows and smooth\nanimations for an intuitive user experience.\n• Emotion Classification from Speech – Built a deep learning model to classify human emotions from\naudio/speech data. Extracted acoustic features (MFCCs, spectrograms) and trained neural networks for\nemotion recognition. Designed and tested the model for multi-class emotion detection, with potential\napplications in mental health monitoring and human-computer interaction.\n• AI-powered hand gesture recognition system – allows playing games like Subway Surfers without a\nkeyboard, using only real-time hand movements captured via a webcam. The solution leverages\nMediaPipe and OpenCV for gesture detection and tracking, implementing swipe-based controls (left,\nright, up for jump, down for slide) and triggering in-game actions through simulated keyboard inputs. This\nproject combines computer vision and human-computer interaction techniques to deliver an intuitive,\nhands-free gaming experience.\nCourses & Certifications\nMEC Academy(Offline):\nIntroduction to Software Engineering using C++ | AI DiplomaNational Telecommunication Institute(Offline):\nHuawei ETA Training Program\nHuawei (Online):\nOverview of AI (Final Exam Score 100 / 100) | AI Basic (CRA Training Program) | HCIA-AI V4.0 (Mock Exam Score 916 /\n1000) | AI Technology And Applications (Final Exam Score 88 / 100)\nHP (Online):\nAI For Beginners\nLinkedIn (Online):\nIntroduction to Artificial Intelligence\nKaggle (Online):\nIntroduction to Programming | Python | Computer Vision | Data Visualization | Introduction to Deep Learning | Introduction\nto Machine Learning | Intermediate Machine Learning | Introduction to SQL (BigQuery)\nSoloLearn (Online):\nIntroduction to C++ | Introduction to Java | Intermediate Java | Introduction to JavaScript | Introduction to C# | Intermediate C# |\nIntroduction to SQL | Intermediate SQL | Introduction to Python | Introduction to HTML | Machine Learning for Beginners |\nIntroduction to LLMs | Prompt Engineering\nMahara-Tech (Online):\nJavaFX | Artificial Intelligence For Everyone | Artificial Intelligence For Juniors | Practical Machine Learning for data\nscientists | Applied Deep Learning | Python Programming Basics | Deep Learning for Computer Vision\nSprints (Online):\nAI And Machine Learning Foundation | Mobile Application development by flutter | Product & Project Management\nGoogle Cloud (Online):\nIntroduction to Generative AI | Introduction to Large Language Model\nUdemy (Online):\nAI for data science\nCoursera (Online):\nIntroduction to mobile Application development (IBM)\nCode.org (Online):\nAI For Oceans\nEducation\nCollege of Computers and Artificial Intelligence, Beni Suef National University\nBachelor’s in Computer Science – Expected Graduation: 2026\"\n\nRespond ONLY in a JSON markdown code block, strictly adhering to the following structure:\nThe output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n\n```json\n{\n\t\"full_name\": string  // The candidate's full name.\n\t\"email\": string  // The candidate's email address.\n\t\"education\": string  // A list of the candidate's education entries.\n\t\"skills\": string  // A list of the candidate's technical and soft skills.\n\t\"experience\": string  // A list of the candidate's work experience entries.\n}\n```\nThe schema's fields can be lists, strings, or objects as defined.\n\nThe JSON object must follow the exact schema above, with each field containing the relevant information from the resume text.\n\nFor example, if the resume text did not provide an email address, then the \"email\" field should be an empty string.\n\nDo not include any other fields or use any other data types beyond those defined in the schema.\n\n```json\n{\n\t\"full_name\": \"SeifElden Osama\",\n\t\"email\": \"seifosama708@gmail.com\",\n\t\"education\": \"College of Computers and Artificial Intelligence, Beni Suef National University - Bachelor’s in Computer Science – Expected Graduation: 2026\",\n\t\"skills\": [\n\t\t\"Python\",\n\t\t\"Java\",\n\t\t\"C++\",\n\t\t\"C#\",\n\t\t\"Dart\",\n\t\t\"SQL\",\n\t\t\"HTML5\",\n\t\t\"JavaScript\",\n\t\t\"Object-Oriented Programming (OOP)\",\n\t\t\"Data Structures & Algorithms\",\n\t\t\"Problem Solving (Competitive Programming, Algorithmic Thinking)\",\n\t\t\"MySQL\",\n\t\t\"SQL Server\",\n\t\t\"SQLite\",\n\t\t\"Machine Learning: Supervised Learning, Unsupervised Learning, Feature Engineering, Model Evaluation\",\n\t\t\"Deep Learning: CNNs, RNNs, LSTMs, Transfer Learning\",\n\t\t\"Computer Vision: Image Classification, Object Detection, Image Processing\",\n\t\t\"Natural Language Processing (NLP): Text Classification, Sentiment Analysis, Embeddings\",\n\t\t\"Speech & Audio AI: Emotion Recognition, MFCC Features, Spectrogram Analysis\",\n\t\t\"Predictive Analytics: Regression Models, Time Series Forecasting\",\n\t\t\"TensorFlow\",\n\t\t\"PyTorch\",\n\t\t\"Keras\",\n\t\t\"scikit-learn\",\n\t\t\"NumPy\",\n\t\t\"Pandas\",\n\t\t\"OpenCV\",\n\t\t\"Matplotlib\",\n\t\t\"Seaborn\",\n\t\t\"Plotly\",\n\t\t\"Dash\",\n\t\t\"JavaFX\",\n\t\t\"Flutter\",\n\t\t\"Swing\",\n\t\t\"Tkinter\",\n\t\t\"Git\",\n\t\t\"GitHub\",\n\t\t\"Arduino\"\n\t],\n\t\"experience\": [\n\t\t{\n\t\t\t\"position\": \"Mastered core concepts of AI and Machine Learning, including Supervised and Unsupervised Learning, Feature Engineering, and Model Evaluation\",\n\t\t\t\"company\": \"National Telecommunication Institute (NTI) – ETA Training Program (On-Site) - Egypt (New Capital)\",\n\t\t\t\"date\": \"Not specified\"\n\t\t},\n\t\t{\n\t\t\t\"position\": \"Developed ML and deep learning models for credit scoring, emotion recognition, handwriting recognition, and disease prediction\",\n\t\t\t\"company\": \"CodeAlpha – Machine Learning Intern & Python Programming Intern (Remote)\",\n\t\t\t\"date\": \"Not specified\"\n\t\t},\n\t\t{\n\t\t\t\"position\": \"Performed customer churn analysis with EDA, segmentation, and churn prediction models\",\n\t\t\t\"company\": \"Saiket Systems – Data Science Intern (Remote)\",\n\t\t\t\"date\": \"Not specified\"\n\t\t},\n\t\t{\n\t\t\t\"position\": \"Implemented supervised and unsupervised learning and deep learning models\",\n\t\t\t\"company\": \"Codveda – Machine Learning Intern (Remote)\",\n\t\t\t\"date\": \"Not specified\"\n\t\t}\n\t]\n}\n```\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"def extract_json_block(text):\n    pattern = r'```json\\s*(.*?)\\s*```'\n    matches = re.findall(pattern, text, re.DOTALL)\n\n    return f\"```json\\n{matches[-1]}\\n```\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T19:11:12.789271Z","iopub.execute_input":"2025-11-11T19:11:12.789655Z","iopub.status.idle":"2025-11-11T19:11:12.794135Z","shell.execute_reply.started":"2025-11-11T19:11:12.789627Z","shell.execute_reply":"2025-11-11T19:11:12.793417Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"json_text = extract_json_block(response)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T19:11:16.240400Z","iopub.execute_input":"2025-11-11T19:11:16.241322Z","iopub.status.idle":"2025-11-11T19:11:16.244685Z","shell.execute_reply.started":"2025-11-11T19:11:16.241293Z","shell.execute_reply":"2025-11-11T19:11:16.243980Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"output_data = output_parser.parse(json_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T19:11:16.478177Z","iopub.execute_input":"2025-11-11T19:11:16.478393Z","iopub.status.idle":"2025-11-11T19:11:16.535195Z","shell.execute_reply.started":"2025-11-11T19:11:16.478376Z","shell.execute_reply":"2025-11-11T19:11:16.534621Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"output_data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T19:11:17.983425Z","iopub.execute_input":"2025-11-11T19:11:17.983712Z","iopub.status.idle":"2025-11-11T19:11:17.989194Z","shell.execute_reply.started":"2025-11-11T19:11:17.983689Z","shell.execute_reply":"2025-11-11T19:11:17.988429Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"{'full_name': 'SeifElden Osama',\n 'email': 'seifosama708@gmail.com',\n 'education': 'College of Computers and Artificial Intelligence, Beni Suef National University - Bachelor’s in Computer Science – Expected Graduation: 2026',\n 'skills': ['Python',\n  'Java',\n  'C++',\n  'C#',\n  'Dart',\n  'SQL',\n  'HTML5',\n  'JavaScript',\n  'Object-Oriented Programming (OOP)',\n  'Data Structures & Algorithms',\n  'Problem Solving (Competitive Programming, Algorithmic Thinking)',\n  'MySQL',\n  'SQL Server',\n  'SQLite',\n  'Machine Learning: Supervised Learning, Unsupervised Learning, Feature Engineering, Model Evaluation',\n  'Deep Learning: CNNs, RNNs, LSTMs, Transfer Learning',\n  'Computer Vision: Image Classification, Object Detection, Image Processing',\n  'Natural Language Processing (NLP): Text Classification, Sentiment Analysis, Embeddings',\n  'Speech & Audio AI: Emotion Recognition, MFCC Features, Spectrogram Analysis',\n  'Predictive Analytics: Regression Models, Time Series Forecasting',\n  'TensorFlow',\n  'PyTorch',\n  'Keras',\n  'scikit-learn',\n  'NumPy',\n  'Pandas',\n  'OpenCV',\n  'Matplotlib',\n  'Seaborn',\n  'Plotly',\n  'Dash',\n  'JavaFX',\n  'Flutter',\n  'Swing',\n  'Tkinter',\n  'Git',\n  'GitHub',\n  'Arduino'],\n 'experience': [{'position': 'Mastered core concepts of AI and Machine Learning, including Supervised and Unsupervised Learning, Feature Engineering, and Model Evaluation',\n   'company': 'National Telecommunication Institute (NTI) – ETA Training Program (On-Site) - Egypt (New Capital)',\n   'date': 'Not specified'},\n  {'position': 'Developed ML and deep learning models for credit scoring, emotion recognition, handwriting recognition, and disease prediction',\n   'company': 'CodeAlpha – Machine Learning Intern & Python Programming Intern (Remote)',\n   'date': 'Not specified'},\n  {'position': 'Performed customer churn analysis with EDA, segmentation, and churn prediction models',\n   'company': 'Saiket Systems – Data Science Intern (Remote)',\n   'date': 'Not specified'},\n  {'position': 'Implemented supervised and unsupervised learning and deep learning models',\n   'company': 'Codveda – Machine Learning Intern (Remote)',\n   'date': 'Not specified'}]}"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"print(type(output_data))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T19:11:27.945813Z","iopub.execute_input":"2025-11-11T19:11:27.946119Z","iopub.status.idle":"2025-11-11T19:11:27.950274Z","shell.execute_reply.started":"2025-11-11T19:11:27.946096Z","shell.execute_reply":"2025-11-11T19:11:27.949564Z"}},"outputs":[{"name":"stdout","text":"<class 'dict'>\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}